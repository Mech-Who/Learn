{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、初见网络爬虫\n",
    "\n",
    "## 1.1 网络连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "print(html.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 BeautifulSoup简介\n",
    "\n",
    "### 1.2.1 BeautifulSoup基础使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bs.h1=<h1>An Interesting Title</h1>\n",
      "bs.html.body.h1=<h1>An Interesting Title</h1>\n",
      "bs.body.h1=<h1>An Interesting Title</h1>\n",
      "bs.html.h1=<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "\n",
    "print(f\"{bs.h1=}\")\n",
    "print(f\"{bs.html.body.h1=}\")\n",
    "print(f\"{bs.body.h1=}\")\n",
    "print(f\"{bs.html.h1=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 异常处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "try:\n",
    "    html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "    # 中断程序\n",
    "else:\n",
    "    # 继续运行程序。\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 502: Bad Gateway HTTPError: this is a HTTPError\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError, URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen('http://pythonscrapingwrong.com/this/url/does/not/exist')\n",
    "except HTTPError as e:\n",
    "    print(e, 'HTTPError: this is a HTTPError')\n",
    "except URLError as e:\n",
    "    print('The server could not be found!')\n",
    "else:\n",
    "    print('It worked!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag was not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_42904\\2524236393.py:2: DeprecationWarning: .nonExistingTag is deprecated, use .find(\"nonExisting\") instead. If you really were looking for a tag called nonExistingTag, use .find(\"nonExistingTag\")\n",
      "  badContent = bs.nonExistingTag.anotherTag\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    badContent = bs.nonExistingTag.anotherTag\n",
    "except AttributeError as e:\n",
    "    print('Tag was not found')\n",
    "else:\n",
    "    if badContent == None:\n",
    "        print('Tag was not found')\n",
    "    else:\n",
    "        print(badContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    try:\n",
    "        bs = BeautifulSoup(html.read(),'html.parser')\n",
    "        title = bs.body.h1\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return title\n",
    "\n",
    "title = getTitle('http://pythonscraping.com/pages/page1.html')\n",
    "if title == None:\n",
    "    print('Title could not be found')\n",
    "else:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
